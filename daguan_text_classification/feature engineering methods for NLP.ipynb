{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "# 只用词来作特征\n",
    "df_train = pd.read_csv('C:/daguan_text_classification/new_data/train_set.csv')\n",
    "df_train.drop(columns='article', inplace=True)\n",
    "df_test = pd.read_csv('C:/daguan_text_classification/new_data/test_set.csv')\n",
    "df_test.drop(columns='article', inplace=True)\n",
    "f_all = pd.concat(objs=[df_train, df_test], axis=0, sort=True)\n",
    "y_train = (df_train['class'] - 1).values\n",
    "\n",
    "#tfidf transformation\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, sublinear_tf=True)\n",
    "vectorizer.fit(df_train['word_seg'])\n",
    "x_train = vectorizer.transform(df_train['word_seg'])\n",
    "x_test = vectorizer.transform(df_test['word_seg'])\n",
    "\n",
    "data = (x_train, y_train, x_test)\n",
    "fp = open('./data_tfidf.pkl', 'wb')\n",
    "pickle.dump(data, fp)\n",
    "fp.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"已将原始数据数字化为tfidf特征，共耗时：{}min\".format((t_end-t_start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"读取tfidf特征\"\"\"\n",
    "tfidf_path = './data_tfidf_selected_lsvc_l2_143w.pkl'\n",
    "f_tfidf = open(tfidf_path, 'rb')\n",
    "x_train, y_train, x_test = pickle.load(f_tfidf)\n",
    "f_tfidf.close()\n",
    "\n",
    "\"\"\"特征降维：lsa\"\"\"\n",
    "print(\"lsa......\")\n",
    "lsa = TruncatedSVD(n_components=200)\n",
    "x_train = lsa.fit_transform(x_train)\n",
    "x_test = lsa.transform(x_test)\n",
    "\n",
    "\n",
    "data = (x_train, y_train, x_test)\n",
    "f_data = open('./data_s_lsvc_l2_143w_lsa.pkl', 'wb')\n",
    "pickle.dump(data, f_data)\n",
    "f_data.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"lsa特征完成，共耗时：{}min\".format((t_end-t_start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#@brief : 将tf特征降维为lda特征，并将结果保存至本地\n",
    "\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "1 tf特征加载\n",
    "\"\"\"\n",
    "tf_path = './tf_select_LSVC_l2644235.pkl'\n",
    "f_tf = open(tf_path, 'rb')\n",
    "x_train, y_train, x_test = pickle.load(f_tf)\n",
    "f_tf.close()\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "2 特征降维：lda\n",
    "\"\"\"\n",
    "print(\"lda......\")\n",
    "lda = LatentDirichletAllocation(n_components=200)\n",
    "x_train = lda.fit_transform(x_train)\n",
    "x_test = lda.transform(x_test)\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "3 将lda特征保存至本地\n",
    "\"\"\"\n",
    "data = (x_train, y_train, x_test)\n",
    "f_data = open('./data_lda.pkl', 'wb')\n",
    "pickle.dump(data, f_data)\n",
    "f_data.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"lda特征完成，共耗时：{}min\".format((t_end-t_start)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#@brief : 将tfidf特征降维为nmf特征，并将结果保存至本地\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"读取tfidf特征\"\"\"\n",
    "tfidf_path = './word_seg_tfidf_(1, 3)-2036592-616882-192632-62375.pkl'\n",
    "f_tfidf = open(tfidf_path, 'rb')\n",
    "x_train, y_train, x_test = pickle.load(f_tfidf)\n",
    "f_tfidf.close()\n",
    "\"\"\"特征降维：nmf\"\"\"\n",
    "#print(\"nmf......\")\n",
    "num_features = 200\n",
    "nmf = NMF(n_components=num_features)\n",
    "x_train = nmf.fit_transform(x_train)\n",
    "x_test = nmf.transform(x_test)\n",
    "\n",
    "\"\"\"将lsa特征保存至本地\"\"\"\n",
    "data = (x_train, y_train, x_test)\n",
    "data_path = tfidf_path[:-4] + '-nmf.pkl'\n",
    "f_data = open(data_path, 'wb')\n",
    "pickle.dump(data, f_data)\n",
    "f_data.close()\n",
    "\n",
    "t_end = time.time()\n",
    "#print(\"nmf特征完成，共耗时：{}min\".format((t_end-t_start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@brief : 将原始数据数字化为doc2vec特征，并将结果保存至本地\n",
    "@author: Jian\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "0 辅助函数 \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sentence2list(sentence):\n",
    "    s_list = sentence.strip().split()\n",
    "    return s_list\n",
    "\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "1 读取原始数据，并进行简单处理\n",
    "\"\"\"\n",
    "df_train = pd.read_csv('../data/train_set.csv')\n",
    "df_train.drop(columns='article', inplace=True)\n",
    "df_test = pd.read_csv('../data/test_set.csv')\n",
    "df_test.drop(columns='article', inplace=True)\n",
    "df_all = pd.concat(objs=[df_train, df_test], axis=0, sort=True)\n",
    "y_train = (df_train['class'] - 1).values\n",
    "\n",
    "df_all['word_list'] = df_all['word_seg'].apply(sentence2list)\n",
    "texts = df_all['word_list'].tolist()\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "2 doc2vec\n",
    "\"\"\"\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]\n",
    "model = Doc2Vec(documents, vector_size=200, window=5, min_count=3, workers=4, epochs=25)\n",
    "docvecs = model.docvecs\n",
    "\n",
    "x_train = []\n",
    "for i in range(0, 102277):\n",
    "    x_train.append(docvecs[i])\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "x_test = []\n",
    "for j in range(102277, 204554):\n",
    "    x_test.append(docvecs[j])\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "3 将doc2vec特征保存至本地\n",
    "\"\"\"\n",
    "data = (x_train, y_train, x_test)\n",
    "f_data = open('./data_doc2vec_25.pkl', 'wb')\n",
    "pickle.dump(data, f_data)\n",
    "f_data.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"已将原始数据数字化为doc2vec特征，共耗时：{}min\".format((t_end-t_start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lda + lsa + doc2vec 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#@brief : lda/lsa/doc2vec三种特征进行特征融合，并将结果保存至本地\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "2 读取lda/lsa/doc2vec特征，并对这三种特征进行拼接融合\n",
    "\"\"\"\n",
    "f1 = open('./data_lda.pkl', 'rb')\n",
    "x_train_1, y_train, x_test_1 = pickle.load(f1)\n",
    "f1.close()\n",
    "\n",
    "f2 = open('./data_s_lsvc_l2_143w_lsa.pkl', 'rb')\n",
    "x_train_2, y_train, x_test_2 = pickle.load(f2)\n",
    "f2.close()\n",
    "\n",
    "f3 = open('./data_doc2vec_25.pkl', 'rb')\n",
    "x_train_3, _, x_test_3 = pickle.load(f3)\n",
    "f3.close()\n",
    "\n",
    "x_train = np.concatenate((x_train_1, x_train_2, x_train_3), axis=1)\n",
    "x_test = np.concatenate((x_test_1, x_test_2, x_test_3), axis=1)\n",
    "\n",
    "\"\"\"=====================================================================================================================\n",
    "2 将融合后的特征，保存至本地\n",
    "\"\"\"\n",
    "data = (x_train, y_train, x_test)\n",
    "fp = open('./data_ensemble.pkl', 'wb')\n",
    "pickle.dump(data, fp)\n",
    "fp.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"已将原始数据数字化为融合的特征，共耗时：{}min\".format((t_end-t_start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#@简介：将data_ensemble特征转换为稀疏矩阵，并将其合并到tfidf\n",
    "\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\"\"\"读取ensemble特征\"\"\"\n",
    "f_ensemble = open('./data_ensemble.pkl', 'rb')\n",
    "x_train_ens, y_train, x_test_ens = pickle.load(f_ensemble)\n",
    "f_ensemble.close()\n",
    "\n",
    "\"\"\"将numpy 数组 转换为 csr稀疏矩阵\"\"\"\n",
    "x_train_ens_s = sparse.csr_matrix(x_train_ens)\n",
    "x_test_ens_s = sparse.csc_matrix(x_test_ens)\n",
    "\n",
    "\"\"\"读取tfidf特征\"\"\"\n",
    "f_tfidf = open('./data_tfidf_select_LSVC_l2_17107.pkl', 'rb')\n",
    "x_train_tfidf, _, x_test_tfidf = pickle.load(f_tfidf)\n",
    "f_tfidf.close()\n",
    "\n",
    "\"\"\"对两个稀疏矩阵进行合并\"\"\"\n",
    "x_train_spar = hstack([x_train_ens_s, x_train_tfidf])\n",
    "x_test_spar = hstack([x_test_ens_s, x_test_tfidf])\n",
    "\n",
    "\"\"\"将合并后的稀疏特征保存至本地\"\"\"\n",
    "data = (x_train_spar, y_train, x_test_spar)\n",
    "f = open('./data_ensemble_spar.pkl', 'wb')\n",
    "pickle.dump(data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#@简介：根据已有的特征，使用多项式方法构造出更多特征\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"读取原特征\"\"\"\n",
    "features_path = './data_s_lsvc_l2_143w_lsa.pkl'\n",
    "f = open(features_path, 'rb')\n",
    "x_train, y_train, x_test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\"\"\"使用多项式方法构造出更多的特征\"\"\"\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)#degree控制多项式最高次数\n",
    "x_train_new = poly.fit_transform(x_train)\n",
    "x_test_new = poly.transform(x_test)\n",
    "\n",
    "\"\"\"将构造好的特征保存至本地\"\"\"\n",
    "data = (x_train_new, y_train,  x_test_new)\n",
    "features_constr_path = features_path.split('/')[-1] + '_constr.pkl'\n",
    "f_data = open(features_constr_path, 'wb')\n",
    "pickle.dump(data, f_data)\n",
    "f_data.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"构造特征完成，共耗时：{}min\".format((t_end-t_start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#@简介：对特征进行嵌入式选择\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "\"\"\"读取特征\"\"\"\n",
    "features_path = './data_tfidf_select_LSVC_l2_901288_select_LSVC_l2_279950.pkl'#tfidf特征的路径\n",
    "fp = open(features_path, 'rb')\n",
    "x_train, y_train, x_test = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "\"\"\"进行特征选择\"\"\"\n",
    "alo_name = 'LSVC_l2'\n",
    "lsvc = LinearSVC(penalty='l2', C=1.0, dual=True).fit(x_train, y_train)\n",
    "slt = SelectFromModel(lsvc, prefit=True)\n",
    "x_train_s = slt.transform(x_train)\n",
    "x_test_s = slt.transform(x_test)\n",
    "\n",
    "\"\"\"保存选择后的特征至本地\"\"\"\n",
    "num_features = x_train_s.shape[1]\n",
    "data_path = './' + features_path.split('.')[-2] + '_select_' + alo_name + '_' + str(num_features) + '.pkl'\n",
    "data_f = open(data_path, 'wb') \n",
    "pickle.dump((x_train_s, y_train, x_test_s), data_f)\n",
    "data_f.close()\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"特征选择完成，选择{}个特征，共耗时{}min\".format(num_features, (t_end-t_start)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
